# -*- coding: utf-8 -*-
"""Copy of VGG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R7B7RbgzhKFlA_KISDwofRZbvq6CzGNM

**VGG Network**
"""

!wget http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat
!wget https://img.theculturetrip.com/768x432/wp-content/uploads/2018/05/tubingen-2867769_1280-1.jpg
!wget https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1280px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg

import tensorflow as tf
import scipy.io as sio
import numpy as np

# this has been changed to take as input 
# the input image (so the content image or style image or the trainable image (the image that has both content and style))
# model_weights is the path to the weights of the VGG net
# returns a dictionary with keys corresponding to layer name and values corresponding to the value of the network at that layer
def build_model(input_image, model_weights):
  net = {}
  vgg_rawnet     = sio.loadmat(model_weights)
  vgg_layers     = vgg_rawnet['layers'][0]
  net['input']   = input_image

  print('LAYER GROUP 1')
  net['conv1_1'] = conv_layer('conv1_1', net['input'], W=get_weights(vgg_layers, 0))
  net['relu1_1'] = relu_layer('relu1_1', net['conv1_1'], b=get_bias(vgg_layers, 0))

  net['conv1_2'] = conv_layer('conv1_2', net['relu1_1'], W=get_weights(vgg_layers, 2))
  net['relu1_2'] = relu_layer('relu1_2', net['conv1_2'], b=get_bias(vgg_layers, 2))
  
  net['pool1']   = pool_layer('pool1', net['relu1_2'])

  print('LAYER GROUP 2')  
  net['conv2_1'] = conv_layer('conv2_1', net['pool1'], W=get_weights(vgg_layers, 5))
  net['relu2_1'] = relu_layer('relu2_1', net['conv2_1'], b=get_bias(vgg_layers, 5))
  
  net['conv2_2'] = conv_layer('conv2_2', net['relu2_1'], W=get_weights(vgg_layers, 7))
  net['relu2_2'] = relu_layer('relu2_2', net['conv2_2'], b=get_bias(vgg_layers, 7))
  
  net['pool2']   = pool_layer('pool2', net['relu2_2'])
  
  print('LAYER GROUP 3')
  net['conv3_1'] = conv_layer('conv3_1', net['pool2'], W=get_weights(vgg_layers, 10))
  net['relu3_1'] = relu_layer('relu3_1', net['conv3_1'], b=get_bias(vgg_layers, 10))

  net['conv3_2'] = conv_layer('conv3_2', net['relu3_1'], W=get_weights(vgg_layers, 12))
  net['relu3_2'] = relu_layer('relu3_2', net['conv3_2'], b=get_bias(vgg_layers, 12))

  net['conv3_3'] = conv_layer('conv3_3', net['relu3_2'], W=get_weights(vgg_layers, 14))
  net['relu3_3'] = relu_layer('relu3_3', net['conv3_3'], b=get_bias(vgg_layers, 14))

  net['conv3_4'] = conv_layer('conv3_4', net['relu3_3'], W=get_weights(vgg_layers, 16))
  net['relu3_4'] = relu_layer('relu3_4', net['conv3_4'], b=get_bias(vgg_layers, 16))

  net['pool3']   = pool_layer('pool3', net['relu3_4'])

  print('LAYER GROUP 4')
  net['conv4_1'] = conv_layer('conv4_1', net['pool3'], W=get_weights(vgg_layers, 19))
  net['relu4_1'] = relu_layer('relu4_1', net['conv4_1'], b=get_bias(vgg_layers, 19))

  net['conv4_2'] = conv_layer('conv4_2', net['relu4_1'], W=get_weights(vgg_layers, 21))
  net['relu4_2'] = relu_layer('relu4_2', net['conv4_2'], b=get_bias(vgg_layers, 21))

  net['conv4_3'] = conv_layer('conv4_3', net['relu4_2'], W=get_weights(vgg_layers, 23))
  net['relu4_3'] = relu_layer('relu4_3', net['conv4_3'], b=get_bias(vgg_layers, 23))

  net['conv4_4'] = conv_layer('conv4_4', net['relu4_3'], W=get_weights(vgg_layers, 25))
  net['relu4_4'] = relu_layer('relu4_4', net['conv4_4'], b=get_bias(vgg_layers, 25))

  net['pool4']   = pool_layer('pool4', net['relu4_4'])

  print('LAYER GROUP 5')
  net['conv5_1'] = conv_layer('conv5_1', net['pool4'], W=get_weights(vgg_layers, 28))
  net['relu5_1'] = relu_layer('relu5_1', net['conv5_1'], b=get_bias(vgg_layers, 28))

  net['conv5_2'] = conv_layer('conv5_2', net['relu5_1'], W=get_weights(vgg_layers, 30))
  net['relu5_2'] = relu_layer('relu5_2', net['conv5_2'], b=get_bias(vgg_layers, 30))

  net['conv5_3'] = conv_layer('conv5_3', net['relu5_2'], W=get_weights(vgg_layers, 32))
  net['relu5_3'] = relu_layer('relu5_3', net['conv5_3'], b=get_bias(vgg_layers, 32))

  net['conv5_4'] = conv_layer('conv5_4', net['relu5_3'], W=get_weights(vgg_layers, 34))
  net['relu5_4'] = relu_layer('relu5_4', net['conv5_4'], b=get_bias(vgg_layers, 34))

  net['pool5']   = pool_layer('pool5', net['relu5_4'])

  return net

def conv_layer(layer_name, layer_input, W):
  conv = tf.nn.conv2d(layer_input, W, strides=[1, 1, 1, 1], padding='SAME')
  return conv

def relu_layer(layer_name, layer_input, b):
  relu = tf.nn.relu(layer_input + b)
  return relu

def pool_layer(layer_name, layer_input):
  pool = tf.nn.avg_pool(layer_input, ksize=[1, 2, 2, 1], 
      strides=[1, 2, 2, 1], padding='SAME')
  return pool

def get_weights(vgg_layers, i):
  weights = vgg_layers[i][0][0][2][0][0]
  W = tf.constant(weights)
  return W

def get_bias(vgg_layers, i):
  bias = vgg_layers[i][0][0][2][0][1]
  b = tf.constant(np.reshape(bias, (bias.size)))
  return b

"""Get Images"""

import PIL.Image
from matplotlib import pyplot as plt

content_image = PIL.Image.open('/content/IMG_8149.JPG')
w, h = content_image.size
d = 3

plt.imshow(content_image)

# reshape style and content images to the same size
style_image = PIL.Image.open('/content/bobross.jpg')
style_image = style_image.resize((w, h), PIL.Image.LANCZOS)
style_image = np.array(style_image)
plt.imshow(style_image)

# our inputs are 3d images [w, h, d] but tensorflow expects 4: [None, w, h, d]
print(style_image.shape)
style_image = np.expand_dims(style_image, axis=0)
content_image = np.expand_dims(content_image, axis=0)
print(style_image.shape)
print(content_image.shape)
_, w, h, d = style_image.shape

from google.colab import drive
drive.mount('/content/drive')

"""Define Graph"""

content_layers = ['conv4_2']
style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']#

final_image = tf.Variable(content_image, trainable=True, dtype=tf.float32)
style_input = tf.placeholder(tf.float32, shape=[None, w, h, d])
content_input = tf.placeholder(tf.float32, shape=[None, w, h, d])

# define nets for content, image, final_image
final_image_net = build_model(final_image, '/content/imagenet-vgg-verydeep-19.mat')
content_image_net = build_model(content_input, '/content/imagenet-vgg-verydeep-19.mat')
style_image_net = build_model(style_input, '/content/imagenet-vgg-verydeep-19.mat')

def gram_matrix(tensor):
  # reshape tensor into [w*h, d] with tensorflow
  # multiply tensor.T * tensor (transpose with tensorflow)
  # 40 x 40 x 3, need to flatten it
  # tf.reshape into 1600 x 3
  shape = tensor.get_shape()
  tensor = tf.reshape(tensor, (-1, int(shape[3])))
  # tensor = tf.reshape(tensor, shape=(-1, d))
  tensor = tf.matmul(tf.transpose(tensor), tensor) 
  return tensor

# define loss
# content loss is the mse between the two layers
# 
content_loss = 0
# style is mse between gram matrices
style_loss = 0
for layer in final_image_net.keys():
  if layer in content_layers:
    content_loss += tf.reduce_sum((final_image_net[layer] - content_image_net[layer]) ** 2)
  if layer in style_layers:
    style_loss += tf.reduce_sum((gram_matrix(final_image_net[layer]) - gram_matrix(style_image_net[layer])) ** 2) # loss in layer
total_loss = 1e-6 * content_loss / len(content_layers) + style_loss / len(style_layers)

# define optimizer
# scale content loss 
optimizer = tf.contrib.opt.ScipyOptimizerInterface(total_loss, method='L-BFGS-B', options={'maxiter': 1000})
def print_img(total_loss, final_image):
  plt.imshow(final_image[0,:,:,:].astype(int))
  plt.show()
  print(total_loss)
  
with tf.Session() as sess:
  # pull in the value of the session 
  sess.run(tf.global_variables_initializer())
  optimizer.minimize(sess, fetches=[total_loss, final_image], loss_callback=print_img, feed_dict={style_input: style_image, content_input: content_image})
  # [1, w, h, 3]
  final_img = sess.run(final_image)
  print(final_img)
  plt.imshow(final_img[0,:,:,:].astype(int))
  
  # call optimizer while feeding in the content and style images



