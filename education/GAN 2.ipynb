{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# import tensorflow and tensorflow_datasets\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# import random stuff that hopefully?? is going to be useful\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "n_z_input = 150\n",
    "\n",
    "# number of epochs and iterations per epoch\n",
    "n_epoch = 40\n",
    "iterations_per_epoch = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a series of graph_images ([#images, :, :, 0]) and plot them\n",
    "# each image is displayed as a 50 by 50 pixel image\n",
    "# where images are laid out in rows of 10 images and columns of 20\n",
    "def display_graph(graph_images, title, shape=(10, 20), image_size=(50, 50)):\n",
    "    fig = plt.figure(figsize=image_size) # define figure\n",
    "    plt.title(title) # define title\n",
    "    plt.axis('off') # remove axis\n",
    "    for i in range(0, shape[0] * shape[1]):\n",
    "        img = graph_images[i, :, :, 0]\n",
    "        fig.add_subplot(shape[0], shape[1], i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator and discriminator \n",
    "def generator(features, reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # tf.layers.conv2d_transpose\n",
    "        # # kernels | kernel dimension | stride | padding | activation\n",
    "        #  512        [4, 4]            (1, 1),   \"VALID\"   relu\n",
    "        #  256        [4, 4]            (4, 4),   \"SAME\"    relu\n",
    "        #  128        [4, 4]            (2, 2),   \"SAME\"    relu\n",
    "        #  1          [4, 4]            (2, 2),   \"SAME\"    relu\n",
    "        # conv3 is the output of the last conv2d_transpose layer\n",
    "        return tf.nn.tanh(conv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(features, reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # # kernels | kernel dimension | stride | padding | activation\n",
    "        #  128        [4, 4]             (2, 2),  \"SAME\"    leaky_relu\n",
    "        #  256        [4, 4]             (2, 2),  \"SAME\"    leaky_relu\n",
    "        #  512        [4, 4]             (4, 4),  \"SAME\"    leaky_relu\n",
    "        #  1024       [3, 3]             (1, 1),  \"VALID\"   leaky_relu\n",
    "        # conv4 is the output of the last conv2d_transpose layer\n",
    "        flatten = tf.contrib.layers.flatten(conv4)\n",
    "        logits = tf.layers.dense(flatten, 1)\n",
    "        # use sigmoid to squash output into a probability\n",
    "        output = tf.nn.sigmoid(logits) \n",
    "        \n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 64, 64, 1))\n",
    "z = tf.placeholder(tf.float32, shape=(None, 1, 1, n_z_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator is generating an image (g is the fake image)\n",
    "g = generator(z, False)\n",
    "# discriminator is classifying real images \n",
    "# the first output is the probability and the second is the logits\n",
    "# to feed into sigmoid_cross_entropy_with_logits\n",
    "disc_real, disc_real_logits = discriminator(x, False)\n",
    "disc_fake, disc_fake_logits = discriminator(g, True)\n",
    "\n",
    "# get accuracy of the discriminator in\n",
    "# predicting that the image is real or fake\n",
    "\n",
    "# the goal is to get a list of 1 and 0 whether it predicted right or not\n",
    "# and use tf.reduce_mean to get mean of 1 and 0 which returns a probability\n",
    "# you can use > or < 0.5 to get true and false \n",
    "# whether it predicted right or not and use tf.cast to cast that boolean into tf.float32\n",
    "real_accuracy = tf.reduce_mean() # TODO\n",
    "fake_accuracy = tf.reduce_mean() # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important! The labels are tf.ones([batch_size, 1]) instead of tf.ones([batch_size, 1, 1, 1]) because the output of the discriminator is a single probability i.e. [batch_size, 0.5] instead of [batch_size, 0.5, 1, 1] because its no longer the output of a conv layer but the output of a dense layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for discriminator\n",
    "disc_loss_real = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_real, labels=tf.ones([batch_size, 1]))\n",
    "disc_loss_real = tf.reduce_mean(disc_loss_real)\n",
    "\n",
    "disc_loss_fake = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake, labels=tf.zeros([batch_size, 1]))\n",
    "disc_loss_fake = tf.reduce_mean(disc_loss_fake)\n",
    "\n",
    "disc_loss_total = disc_loss_real + disc_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for generator\n",
    "gen_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_fake, labels=tf.ones([None, 1]))\n",
    "gen_loss = tf.reduce_mean(gen_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vars = tf.trainable_variables()\n",
    "disc_var = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "gen_var = [var for var in t_vars if var.name.startswith('generator')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    gen_optimizer = tf.train.AdamOptimizer(lr, beta1=0.5).minimize(gen_loss, var_list=gen_vars)\n",
    "    disc_optimizer = tf.train.AdamOptimizer(lr, beta1=0.5).minimize(disc_loss, var_list=disc_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_builder = tfds.builder(\"mnist\")\n",
    "# use https://www.tensorflow.org/datasets/overview#datasetbuilder\n",
    "# dont use split\n",
    "datasets = #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = datasets[\"train\"], datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_map(inputs):\n",
    "    img = inputs['image']\n",
    "    # 1. cast the img into float32\n",
    "    # 2. image values are from 0 to 1. convert to range -1 to 1\n",
    "    # by subtracting by a decimal so its range -0.5 to 0.5 and\n",
    "    # then divide by a decimal so its not -1 to 1\n",
    "    img = tf.math.tanh(img)\n",
    "    # 3. use tf.image.resize to conver the image into a 64 by 64 image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(apply_map)\n",
    "train_dataset = train_dataset.shuffle(1024)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "iterator = train_dataset.make_initializable_iterator()\n",
    "batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_test input into the generator with batch_size 10 \n",
    "z_test = np.random.normal(0, 1, (10, 1, 1, n_z_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    # initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(train_epoch):\n",
    "        print(\"Starting epoch: \" + str(epoch))\n",
    "        # initialize iterator\n",
    "        sess.run(iterator.initializer)\n",
    "        step = 0\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                tra_images = # grab the batch\n",
    "\n",
    "                # makes sure the batch_size is 64\n",
    "                if tra_images.shape[0] != 64:\n",
    "                    break\n",
    "                    \n",
    "                # z vector of size batch_size\n",
    "                z_batch = np.random.normal(0, 1, (batch_size, 1, 1, n_z_input))\n",
    "                \n",
    "                acc_fake, acc_real, loss_d, _, loss_g, _ = sess.run(\n",
    "                  # TODO, which variables to run the session on\n",
    "                  feed_dict={x: tra_images, z: z_batch})\n",
    "                step += 1\n",
    "\n",
    "                if step % 200 == 0:\n",
    "                    generated_images = # get generated images that would result from feeding in z_test\n",
    "                    display_graph(generated_images, \"MNIST Images\", (5, 2), image_size=(20, 20))\n",
    "                print('Epoch: %d, Iteration: %d, loss_d: %.3f, loss_g: %.3f, acc_fake: %.3f, acc_real: %.3f' % (\n",
    "                        epoch, step, loss_d, loss_g, acc_fake, acc_real))\n",
    "                \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
